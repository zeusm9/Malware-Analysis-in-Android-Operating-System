import pandas as pa
import numpy as np
import matplotlib.pyplot as plt
import string
import plot as plotter
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.metrics import make_scorer,accuracy_score, precision_score, recall_score, fbeta_score
from sklearn.model_selection import StratifiedKFold,KFold,cross_validate

def prepare_data_bayes(data_path,family_classification):
    #make dataframe from dataset.txt
    trainDF = pa.read_table(data_path,sep='\t',header=None,names=['label','features'])
    trainDF = trainDF.dropna()
    if(family_classification == True):
        trainDF = trainDF[trainDF.label != 'safeware']
        trainDF = trainDF[trainDF.groupby('label').label.transform(len) > 0]
    else:
        trainDF.label[trainDF.label != 'safeware'] = 1
        trainDF.label[trainDF.label == 'safeware'] = 0
        fracs = {0: 0, 1: 1 / 5}
        print(trainDF['label'].value_counts())
        trainDF = over_sampling(trainDF,fracs)
        print(trainDF['label'].value_counts())

    trainDF['features'] = trainDF.features.map(lambda  x: x.lower())
    if (family_classification == False):
        trainDF['label'] = trainDF['label'].astype('int')
    count_vect = CountVectorizer(analyzer=text_process)
    counts = count_vect.fit_transform(trainDF['features'])
    return counts,np.array(trainDF['label'])

def prepare_data_svm(data_path,family_classification):
    # make dataframe from dataset.txt
    trainDF = pa.read_table(data_path, sep='\t', header=None, names=['label', 'features'])
    #take a fraction of the dataset
    trainDF = trainDF.sample(frac=0.5)
    #remove missing values
    trainDF = trainDF.dropna()

    if(family_classification == True):
        trainDF = trainDF[trainDF.label != 'safeware']
        #take most frequent samples
        trainDF = trainDF[trainDF.groupby('label').label.transform(len)>10]
        print("ok")
    else:
        print("not ok")
        #1 for malware, 0 for safeware
        trainDF.label[trainDF.label != 'safeware'] = 1
        trainDF.label[trainDF.label == 'safeware'] = 0
        fracs = {0: 1 /15, 1: 1 / 25}
        #oversampling on the dataframe to balance it
        trainDF = over_sampling(trainDF,fracs)


    #clean features text
    trainDF['features'] = trainDF.features.map(lambda x: x.lower())
    trainDF['features'] = trainDF['features'].apply(text_process)
    #one hot encoding
    trainDF = trainDF.drop('features',1).join(trainDF.features.str.join('|').str.get_dummies())
    if(family_classification == False):
        trainDF['label'] = trainDF['label'].astype('int')
    return trainDF.drop('label',axis=1),np.array(trainDF['label'])

def text_process(mess):
    # Remove punctuation
    nopunc = [char for char in mess if char not in string.punctuation]
    nopunc = ''.join(nopunc)
    return nopunc.split()

def validation(estimator, X, y,family_classification):
    if(family_classification == True):
        av = "macro"
    else:
        av= "binary"
    #The folds are made by preserving the percentage of samples for each class with stratified_kfold.
    s_kfold = StratifiedKFold(10, True, 1)

    scoringMalware = {
        'accuracy': make_scorer(accuracy_score),
        'precision': make_scorer(precision_score, pos_label=1,average=av),
        'recall': make_scorer(recall_score, pos_label=1,average=av),
        'f1': make_scorer(fbeta_score, beta=1, pos_label=1,average=av)
    }

    plot(estimator, X, y, s_kfold)
    scores = cross_validate(estimator, X, y, cv=s_kfold, scoring=scoringMalware)
    return np.mean(scores['test_accuracy']), np.mean(scores['test_precision']), np.mean(scores['test_recall']), np.mean(scores['test_f1'])

def plot(estimator,X,y,cv):
    title = "Learning curves"

    plotter.plot_learning_curve(estimator,title,X,y,ylim=(0.6,1.1),n_jobs=-1, cv=cv)
    plt.show()

def over_sampling(trainDF,fracs):

    rand = np.random.RandomState([42])
    lst = [trainDF]
    for class_index,group in trainDF.groupby('label'):
        lst.append(group.sample(n = int(fracs.get(class_index)*len(trainDF)),random_state=rand,replace = True) )
    new_frame = pa.concat(lst)
    return new_frame
